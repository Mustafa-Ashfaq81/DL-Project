{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "dataset_dir = \"RESIDE-6K\"\n",
    "train_zip_path = os.path.join(dataset_dir, \"train.zip\")\n",
    "test_zip_path = os.path.join(dataset_dir, \"test.zip\")\n",
    "\n",
    "final_dataset_dir = \"RESIDE-6K-OUR\"\n",
    "# Create final dataset directory if it doesn't exist\n",
    "if not os.path.exists(final_dataset_dir):\n",
    "    os.makedirs(final_dataset_dir)\n",
    "\n",
    "train_dir = os.path.join(final_dataset_dir, \"train\")\n",
    "test_dir = os.path.join(final_dataset_dir, \"test\")\n",
    "\n",
    "train_gt_dir = os.path.join(train_dir, \"GT\")\n",
    "train_hazy_dir = os.path.join(train_dir, \"hazy\")\n",
    "\n",
    "test_gt_dir = os.path.join(test_dir, \"GT\")\n",
    "test_hazy_dir = os.path.join(test_dir, \"hazy\")\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "    os.makedirs(train_gt_dir)\n",
    "    os.makedirs(train_hazy_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "    os.makedirs(test_gt_dir)\n",
    "    os.makedirs(test_hazy_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESIDE-6K/train\n",
      "Number of images in train dataset:\n",
      "GT: 6000\n",
      "HAZY: 6000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RESIDE-6K/test\n",
      "Number of images in test dataset:\n",
      "GT: 1000\n",
      "HAZY: 1000\n"
     ]
    }
   ],
   "source": [
    "# Extract images from train.zip and test.zip\n",
    "def extract_images(zip_path, output_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "    return os.listdir(output_dir)\n",
    "\n",
    "# Extract images train\n",
    "extracted_train = extract_images(train_zip_path, dataset_dir)\n",
    "extracted_train_path = dataset_dir + '/train'\n",
    "print(extracted_train_path)\n",
    "print(\"Number of images in train dataset:\")\n",
    "print(f\"GT: {len(os.listdir(extracted_train_path+'/GT'))}\")\n",
    "print(f\"HAZY: {len(os.listdir(extracted_train_path+'/hazy'))}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Extract images test\n",
    "extracted_test = extract_images(test_zip_path, dataset_dir)\n",
    "extracted_test_path = dataset_dir + '/test'\n",
    "print(extracted_test_path)\n",
    "print(\"Number of images in test dataset:\")\n",
    "print(f\"GT: {len(os.listdir(extracted_test_path+'/GT'))}\")\n",
    "print(f\"HAZY: {len(os.listdir(extracted_test_path+'/hazy'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Test: (100, 100)\n",
      "Selected Train: (100, 100)\n",
      "Final dataset created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Pick 5 random images from extracted images\n",
    "def pick_random_images(extracted_dir, num_images):\n",
    "    images = os.listdir(extracted_dir)\n",
    "    return random.sample(images, num_images)\n",
    "\n",
    "# extracted_train_dir = os.path.join(final_dataset_dir, \"train\")\n",
    "# selected_train_images = pick_random_images(extracted_train_dir, 5)\n",
    "# extracted_test_dir = os.path.join(final_dataset_dir, \"test\")\n",
    "selected_train_images_GT = pick_random_images(extracted_train_path+'/GT', 100)\n",
    "selected_train_images_HAZY = pick_random_images(extracted_train_path+'/hazy', 100)\n",
    "selected_test_images_GT = pick_random_images(extracted_test_path+'/GT', 100)\n",
    "selected_test_images_HAZY = pick_random_images(extracted_test_path+'/hazy', 100)\n",
    "\n",
    "print(f\"Selected Test: {len(selected_train_images_GT), len(selected_train_images_HAZY)}\")\n",
    "print(f\"Selected Train: {len(selected_test_images_GT), len(selected_test_images_HAZY)}\")\n",
    "\n",
    "# Move selected images to train_gt_dir\n",
    "for image in selected_train_images_GT:\n",
    "    shutil.move(os.path.join(extracted_train_path, 'GT', image), os.path.join(train_gt_dir, image))\n",
    "\n",
    "# Move selected images to train_hazy_dir\n",
    "for image in selected_train_images_HAZY:\n",
    "    shutil.move(os.path.join(extracted_train_path, 'hazy', image), os.path.join(train_hazy_dir, image))\n",
    "\n",
    "# Move selected images to test_gt_dir\n",
    "for image in selected_test_images_GT:\n",
    "    shutil.move(os.path.join(extracted_test_path, 'GT', image), os.path.join(test_gt_dir, image))\n",
    "\n",
    "# Move selected images to test_hazy_dir\n",
    "for image in selected_test_images_HAZY:\n",
    "    shutil.move(os.path.join(extracted_test_path, 'hazy', image), os.path.join(test_hazy_dir, image))\n",
    "\n",
    "print(\"Final dataset created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the img passed to model: torch.Size([413, 550, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "img_path = \"dummy_data/RESIDE-OUT/train/GT/0001.png\"\n",
    "\n",
    "img = Image.open(img_path)\n",
    "\n",
    "img_tensor = torch.tensor(np.array(img))\n",
    "\n",
    "print(\"Shape of the img passed to model:\", img_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len train: 48\n",
      "Len val: 48\n",
      "Hazy shape: torch.Size([8, 3, 64, 64])\n",
      "target shape: torch.Size([8, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "from datasets.loader import PairLoader, SingleLoader\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "setting_filename = \"configs/outdoor/dehazeformer-t.json\" #os.path.join('configs', args.exp, args.model+'.json')\n",
    "\n",
    "dataset_dir = \"data/RESIDE-OUT\" #os.path.join(args.data_dir, args.dataset)\n",
    "with open(setting_filename, 'r') as f:\n",
    "    setting = json.load(f)\n",
    "\n",
    "train_dataset = PairLoader(dataset_dir, 'train', 'train', \n",
    "\t\t\t\t\t\t\t\tsetting['patch_size'], setting['edge_decay'], setting['only_h_flip'])\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=setting['batch_size'],\n",
    "                              shuffle=True,\n",
    "                              num_workers=2,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "val_dataset = PairLoader(dataset_dir, 'test', setting['valid_mode'], \n",
    "\t\t\t\t\t\t\t  setting['patch_size'])\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=setting['batch_size'],\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True)\n",
    "\n",
    "print(f'Len train: {len(train_loader)}')\n",
    "print(f'Len val: {len(train_loader)}')\n",
    "\n",
    "for batch in train_loader:\n",
    "    source_img = batch['source']\n",
    "    print(f'Hazy shape: {source_img.shape}')\n",
    "    target_img = batch['target']\n",
    "    print(f'target shape: {source_img.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
